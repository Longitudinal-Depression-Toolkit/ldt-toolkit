from __future__ import annotations

from collections.abc import Mapping
from dataclasses import dataclass
from pathlib import Path
from typing import Any

import miceforest as mf
import pandas as pd
from sklearn.impute import SimpleImputer

from src.data_preprocessing.catalog import resolve_technique_with_defaults
from src.data_preprocessing.support.inputs import (
    as_bool,
    as_choice,
    as_optional_float,
    as_optional_int,
    as_optional_string,
    as_required_int,
    as_required_string,
    ensure_distinct_paths,
    normalise_key,
    run_with_validation,
)
from src.utils.errors import InputValidationError

_SIMPLE_STRATEGIES: tuple[str, ...] = (
    "mean",
    "median",
    "most_frequent",
    "constant",
    "none",
)
_CATEGORICAL_SIMPLE_STRATEGIES: tuple[str, ...] = (
    "most_frequent",
    "constant",
    "none",
)


@dataclass(frozen=True)
class SimpleImputationRequest:
    """Request payload for simple missing-value imputation.

    Attributes:
        input_path (Path): Input CSV path.
        output_path (Path): Output CSV path.
        numeric_strategy (str): Strategy for numeric columns.
        categorical_strategy (str): Strategy for categorical columns.
        numeric_fill_value (float | None): Fill value when numeric strategy is
            `constant`.
        categorical_fill_value (str | None): Fill value when categorical
            strategy is `constant`.
    """

    input_path: Path
    output_path: Path
    numeric_strategy: str
    categorical_strategy: str
    numeric_fill_value: float | None
    categorical_fill_value: str | None


@dataclass(frozen=True)
class SimpleImputationResult:
    """Result payload for simple missing-value imputation.

    Attributes:
        output_path (Path): Output CSV path.
        row_count (int): Number of rows in output dataset.
        column_count (int): Number of columns in output dataset.
        numeric_imputed (int): Number of numeric missing values imputed.
        categorical_imputed (int): Number of categorical missing values imputed.
        missing_after (int): Number of missing cells remaining after imputation.
    """

    output_path: Path
    row_count: int
    column_count: int
    numeric_imputed: int
    categorical_imputed: int
    missing_after: int


@dataclass(frozen=True)
class MICEImputationRequest:
    """Request payload for MICE missing-value imputation.

    Attributes:
        input_path (Path): Input CSV path.
        output_path (Path): Output CSV path.
        iterations (int): Number of MICE iterations.
        num_datasets (int): Number of imputed datasets generated by kernel.
        dataset_index (int): Index of completed dataset to export.
        mean_match_candidates (int): Mean-match candidate count for
            predictive mean matching.
        random_state (int | None): Optional random seed.
        cast_object_to_category (bool): Whether to cast object/string columns
            to categorical before fitting.
    """

    input_path: Path
    output_path: Path
    iterations: int
    num_datasets: int
    dataset_index: int
    mean_match_candidates: int
    random_state: int | None
    cast_object_to_category: bool


@dataclass(frozen=True)
class MICEImputationResult:
    """Result payload for MICE missing-value imputation.

    Attributes:
        output_path (Path): Output CSV path.
        row_count (int): Number of rows in output dataset.
        column_count (int): Number of columns in output dataset.
        missing_before (int): Missing-cell count before imputation.
        missing_after (int): Missing-cell count after imputation.
        iterations (int): Number of MICE iterations executed.
        num_datasets (int): Number of imputed datasets generated.
        dataset_index (int): Exported imputed dataset index.
    """

    output_path: Path
    row_count: int
    column_count: int
    missing_before: int
    missing_after: int
    iterations: int
    num_datasets: int
    dataset_index: int


def run_simple_imputation(request: SimpleImputationRequest) -> SimpleImputationResult:
    """Impute missing values with rule-based `SimpleImputer` strategies.

    This mode applies deterministic imputations separately for numeric and
    categorical columns.

    Supported simple strategies:

    | Column type | Strategy values |
    | --- | --- |
    | Numeric | `mean`, `median`, `most_frequent`, `constant`, `none` |
    | Categorical | `most_frequent`, `constant`, `none` |

    Args:
        request (SimpleImputationRequest): Strategy configuration and
            input/output paths.

    Returns:
        SimpleImputationResult: Output dataset summary and imputation counts.
    """

    _validate_csv_path(request.input_path)
    _validate_output_csv_path(request.output_path, input_path=request.input_path)
    numeric_strategy = _normalise_strategy(
        request.numeric_strategy,
        allowed=_SIMPLE_STRATEGIES,
        field_name="numeric_strategy",
    )
    categorical_strategy = _normalise_strategy(
        request.categorical_strategy,
        allowed=_CATEGORICAL_SIMPLE_STRATEGIES,
        field_name="categorical_strategy",
    )

    data = pd.read_csv(request.input_path)
    imputed = data.copy()
    numeric_columns = imputed.select_dtypes(include=["number"]).columns.tolist()
    categorical_columns = [
        column for column in imputed.columns if column not in numeric_columns
    ]

    numeric_imputed = 0
    if numeric_strategy != "none" and numeric_columns:
        if numeric_strategy == "constant" and request.numeric_fill_value is None:
            raise InputValidationError(
                "numeric_fill_value is required when numeric_strategy is `constant`."
            )
        numeric_imputer = SimpleImputer(
            strategy=numeric_strategy,
            fill_value=(
                request.numeric_fill_value if numeric_strategy == "constant" else None
            ),
        )
        imputed[numeric_columns] = numeric_imputer.fit_transform(
            imputed[numeric_columns]
        )
        numeric_imputed = int(data[numeric_columns].isna().sum().sum())

    categorical_imputed = 0
    if categorical_strategy != "none" and categorical_columns:
        if (
            categorical_strategy == "constant"
            and request.categorical_fill_value is None
        ):
            raise InputValidationError(
                "categorical_fill_value is required when categorical_strategy is `constant`."
            )
        categorical_imputer = SimpleImputer(
            strategy=categorical_strategy,
            fill_value=(
                request.categorical_fill_value
                if categorical_strategy == "constant"
                else None
            ),
        )
        imputed[categorical_columns] = categorical_imputer.fit_transform(
            imputed[categorical_columns]
        )
        categorical_imputed = int(data[categorical_columns].isna().sum().sum())

    request.output_path.parent.mkdir(parents=True, exist_ok=True)
    imputed.to_csv(request.output_path, index=False)

    return SimpleImputationResult(
        output_path=request.output_path.resolve(),
        row_count=len(imputed),
        column_count=int(imputed.shape[1]),
        numeric_imputed=numeric_imputed,
        categorical_imputed=categorical_imputed,
        missing_after=int(imputed.isna().sum().sum()),
    )


def run_mice_imputation(request: MICEImputationRequest) -> MICEImputationResult:
    """Impute missing values with MICE (`miceforest.ImputationKernel`).

    MICE (Multiple Imputation by Chained Equations) iteratively models each
    variable with missing values as a function of other variables, cycling
    through columns until imputations stabilise. This is generally more
    expressive than simple mean/mode filling when missingness depends on other
    observed features.

    Args:
        request (MICEImputationRequest): MICE configuration and input/output
            paths, including iteration count and dataset selection.

    Returns:
        MICEImputationResult: Output dataset summary and MICE run metadata.
    """

    _validate_csv_path(request.input_path)
    _validate_output_csv_path(request.output_path, input_path=request.input_path)
    if request.iterations < 1:
        raise InputValidationError("iterations must be >= 1.")
    if request.num_datasets < 1:
        raise InputValidationError("num_datasets must be >= 1.")
    if request.dataset_index < 0:
        raise InputValidationError("dataset_index must be >= 0.")
    if request.dataset_index >= request.num_datasets:
        raise InputValidationError("dataset_index must be < num_datasets.")
    if request.mean_match_candidates < 0:
        raise InputValidationError("mean_match_candidates must be >= 0.")

    data = pd.read_csv(request.input_path)
    missing_before = int(data.isna().sum().sum())

    if request.cast_object_to_category:
        object_columns = data.select_dtypes(include=["object", "string"]).columns
        for column in object_columns:
            data[column] = data[column].astype("category")

    if missing_before == 0:
        request.output_path.parent.mkdir(parents=True, exist_ok=True)
        data.to_csv(request.output_path, index=False)
        return MICEImputationResult(
            output_path=request.output_path.resolve(),
            row_count=len(data),
            column_count=int(data.shape[1]),
            missing_before=0,
            missing_after=0,
            iterations=request.iterations,
            num_datasets=request.num_datasets,
            dataset_index=request.dataset_index,
        )

    kernel = mf.ImputationKernel(
        data=data,
        num_datasets=request.num_datasets,
        mean_match_candidates=request.mean_match_candidates,
        save_all_iterations_data=True,
        random_state=request.random_state,
    )
    kernel.mice(iterations=request.iterations, verbose=False)
    imputed = kernel.complete_data(dataset=request.dataset_index, inplace=False)

    request.output_path.parent.mkdir(parents=True, exist_ok=True)
    imputed.to_csv(request.output_path, index=False)

    return MICEImputationResult(
        output_path=request.output_path.resolve(),
        row_count=len(imputed),
        column_count=int(imputed.shape[1]),
        missing_before=missing_before,
        missing_after=int(imputed.isna().sum().sum()),
        iterations=request.iterations,
        num_datasets=request.num_datasets,
        dataset_index=request.dataset_index,
    )


def run_missing_imputation_tool(
    *,
    technique: str,
    params: Mapping[str, Any],
) -> dict[str, Any]:
    """Run missing-value imputation techniques from catalog payloads.

    Available imputation techniques:

    | Technique | Method | Best suited for |
    | --- | --- | --- |
    | `simple_imputation` | Deterministic `SimpleImputer` rules | Fast baseline preprocessing. |
    | `mice_imputation` | Iterative multivariate MICE (`miceforest`) | Richer imputations when feature dependencies matter. |

    Args:
        technique (str): Technique identifier (`simple_imputation` or
            `mice_imputation`).
        params (Mapping[str, Any]): Parameters for the selected imputation
            method.

    Returns:
        dict[str, Any]: Output path, row/column counts, and method-specific
            imputation summary fields.

    Examples:
        ```python
        from ldt.data_preprocessing.tools.missing_imputation.run import run_missing_imputation_tool

        result = run_missing_imputation_tool(
            technique="mice_imputation",
            params={
                "input_path": "./data/raw.csv",
                "output_path": "./outputs/imputed.csv",
                "iterations": 5,
                "num_datasets": 3,
                "dataset_index": 0,
                "mean_match_candidates": 5,
                "cast_object_to_category": True,
            },
        )
        ```
    """

    return run_with_validation(
        lambda: _run_missing_imputation_tool(technique=technique, params=params)
    )


def _run_missing_imputation_tool(
    *,
    technique: str,
    params: Mapping[str, Any],
) -> dict[str, Any]:
    _, resolved = resolve_technique_with_defaults(
        section_key="missing_imputation",
        technique_id=technique,
        provided_params=dict(params),
    )

    mode = normalise_key(technique)
    input_path = Path(as_required_string(resolved, "input_path")).expanduser()
    output_path = Path(as_required_string(resolved, "output_path")).expanduser()
    ensure_distinct_paths(input_path, output_path, field_name="output_path")

    if mode == "simple_imputation":
        numeric_strategy = as_choice(
            as_required_string(resolved, "numeric_strategy"),
            choices=("mean", "median", "most_frequent", "constant", "none"),
            field_name="numeric_strategy",
        )
        categorical_strategy = as_choice(
            as_required_string(resolved, "categorical_strategy"),
            choices=("most_frequent", "constant", "none"),
            field_name="categorical_strategy",
        )
        numeric_fill_value = as_optional_float(resolved, "numeric_fill_value")
        categorical_fill_value = as_optional_string(resolved, "categorical_fill_value")

        result = run_simple_imputation(
            SimpleImputationRequest(
                input_path=input_path,
                output_path=output_path,
                numeric_strategy=numeric_strategy,
                categorical_strategy=categorical_strategy,
                numeric_fill_value=numeric_fill_value,
                categorical_fill_value=categorical_fill_value,
            )
        )
        return {
            "mode": "simple",
            "output_path": str(result.output_path),
            "row_count": result.row_count,
            "column_count": result.column_count,
            "missing_after": result.missing_after,
            "numeric_imputed": result.numeric_imputed,
            "categorical_imputed": result.categorical_imputed,
        }

    if mode == "mice_imputation":
        iterations = as_required_int(resolved, "iterations", minimum=1)
        num_datasets = as_required_int(resolved, "num_datasets", minimum=1)
        dataset_index = as_required_int(resolved, "dataset_index", minimum=0)
        if dataset_index >= num_datasets:
            raise InputValidationError("dataset_index must be < num_datasets.")

        mean_match_candidates = as_required_int(
            resolved,
            "mean_match_candidates",
            minimum=0,
        )
        random_state = as_optional_int(resolved, "random_state")
        cast_object_to_category = as_bool(
            resolved.get("cast_object_to_category", True),
            field_name="cast_object_to_category",
        )

        result = run_mice_imputation(
            MICEImputationRequest(
                input_path=input_path,
                output_path=output_path,
                iterations=iterations,
                num_datasets=num_datasets,
                dataset_index=dataset_index,
                mean_match_candidates=mean_match_candidates,
                random_state=random_state,
                cast_object_to_category=cast_object_to_category,
            )
        )
        return {
            "mode": "mice",
            "output_path": str(result.output_path),
            "row_count": result.row_count,
            "column_count": result.column_count,
            "missing_after": result.missing_after,
            "missing_before": result.missing_before,
            "iterations": result.iterations,
            "num_datasets": result.num_datasets,
            "dataset_index": result.dataset_index,
        }

    raise InputValidationError(f"Unsupported missing-imputation mode: {technique}")


def _normalise_strategy(raw: str, *, allowed: tuple[str, ...], field_name: str) -> str:
    value = raw.strip().lower()
    if value not in allowed:
        raise InputValidationError(
            f"{field_name} must be one of: {', '.join(allowed)}."
        )
    return value


def _validate_csv_path(path: Path) -> None:
    if not path.exists():
        raise InputValidationError(f"CSV path does not exist: {path}")
    if not path.is_file():
        raise InputValidationError(f"CSV path is not a file: {path}")
    if path.suffix.lower() != ".csv":
        raise InputValidationError("CSV path must point to a .csv file.")


def _validate_output_csv_path(path: Path, *, input_path: Path) -> None:
    if path.suffix.lower() != ".csv":
        raise InputValidationError("Output path must point to a .csv file.")
    if path.resolve() == input_path.resolve():
        raise InputValidationError("Output path must be different from input path.")
